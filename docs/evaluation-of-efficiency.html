<!DOCTYPE html>
<html >

<head>

  <meta charset="UTF-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <title>Sleep quality analysis</title>
  <meta content="text/html; charset=UTF-8" http-equiv="Content-Type">
  <meta name="description" content="This is a minimal example of using the bookdown package to write a book. The output format for this example is bookdown::gitbook.">
  <meta name="generator" content="bookdown 0.3 and GitBook 2.6.7">

  <meta property="og:title" content="Sleep quality analysis" />
  <meta property="og:type" content="book" />
  
  
  <meta property="og:description" content="This is a minimal example of using the bookdown package to write a book. The output format for this example is bookdown::gitbook." />
  <meta name="github-repo" content="rstudio/bookdown-demo" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Sleep quality analysis" />
  
  <meta name="twitter:description" content="This is a minimal example of using the bookdown package to write a book. The output format for this example is bookdown::gitbook." />
  

<meta name="author" content="Arturo Laflor">


<meta name="date" content="2017-05-09">

  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-status-bar-style" content="black">
  
  
<link rel="prev" href="feature-selection.html">
<link rel="next" href="applications.html">

<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />









<style type="text/css">
div.sourceCode { overflow-x: auto; }
table.sourceCode, tr.sourceCode, td.lineNumbers, td.sourceCode {
  margin: 0; padding: 0; vertical-align: baseline; border: none; }
table.sourceCode { width: 100%; line-height: 100%; }
td.lineNumbers { text-align: right; padding-right: 4px; padding-left: 4px; color: #aaaaaa; border-right: 1px solid #aaaaaa; }
td.sourceCode { padding-left: 5px; }
code > span.kw { color: #007020; font-weight: bold; } /* Keyword */
code > span.dt { color: #902000; } /* DataType */
code > span.dv { color: #40a070; } /* DecVal */
code > span.bn { color: #40a070; } /* BaseN */
code > span.fl { color: #40a070; } /* Float */
code > span.ch { color: #4070a0; } /* Char */
code > span.st { color: #4070a0; } /* String */
code > span.co { color: #60a0b0; font-style: italic; } /* Comment */
code > span.ot { color: #007020; } /* Other */
code > span.al { color: #ff0000; font-weight: bold; } /* Alert */
code > span.fu { color: #06287e; } /* Function */
code > span.er { color: #ff0000; font-weight: bold; } /* Error */
code > span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
code > span.cn { color: #880000; } /* Constant */
code > span.sc { color: #4070a0; } /* SpecialChar */
code > span.vs { color: #4070a0; } /* VerbatimString */
code > span.ss { color: #bb6688; } /* SpecialString */
code > span.im { } /* Import */
code > span.va { color: #19177c; } /* Variable */
code > span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code > span.op { color: #666666; } /* Operator */
code > span.bu { } /* BuiltIn */
code > span.ex { } /* Extension */
code > span.pp { color: #bc7a00; } /* Preprocessor */
code > span.at { color: #7d9029; } /* Attribute */
code > span.do { color: #ba2121; font-style: italic; } /* Documentation */
code > span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code > span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code > span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
</style>

<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>


  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">Notes of feature selection</a></li>

<li class="divider"></li>
<li class="chapter" data-level="1" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i><b>1</b> Prerequisites</a></li>
<li class="chapter" data-level="2" data-path="intro.html"><a href="intro.html"><i class="fa fa-check"></i><b>2</b> Introduction</a></li>
<li class="chapter" data-level="3" data-path="data-adquisition.html"><a href="data-adquisition.html"><i class="fa fa-check"></i><b>3</b> <a href="data-adquisition.html#data-adquisition">Data adquisition</a></a><ul>
<li class="chapter" data-level="3.1" data-path="data-adquisition.html"><a href="data-adquisition.html#questionnaire"><i class="fa fa-check"></i><b>3.1</b> Questionnaire</a><ul>
<li class="chapter" data-level="3.1.1" data-path="data-adquisition.html"><a href="data-adquisition.html#demographic-emotional-and-health-data"><i class="fa fa-check"></i><b>3.1.1</b> Demographic emotional and health data</a></li>
<li class="chapter" data-level="3.1.2" data-path="data-adquisition.html"><a href="data-adquisition.html#quality-of-sleep"><i class="fa fa-check"></i><b>3.1.2</b> Quality of Sleep</a></li>
<li class="chapter" data-level="3.1.3" data-path="data-adquisition.html"><a href="data-adquisition.html#sleep-hygiene-index"><i class="fa fa-check"></i><b>3.1.3</b> Sleep Hygiene Index</a></li>
</ul></li>
<li class="chapter" data-level="3.2" data-path="data-adquisition.html"><a href="data-adquisition.html#validity-and-reliability"><i class="fa fa-check"></i><b>3.2</b> Validity and reliability</a></li>
<li class="chapter" data-level="3.3" data-path="data-adquisition.html"><a href="data-adquisition.html#dataset"><i class="fa fa-check"></i><b>3.3</b> Dataset</a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="data-pre-process.html"><a href="data-pre-process.html"><i class="fa fa-check"></i><b>4</b> <a href="#data-preprocess">Data pre-process</a></a><ul>
<li class="chapter" data-level="4.1" data-path="data-pre-process.html"><a href="data-pre-process.html#estructuration-and-validation-data-process"><i class="fa fa-check"></i><b>4.1</b> Estructuration and validation data process</a></li>
<li class="chapter" data-level="4.2" data-path="data-pre-process.html"><a href="data-pre-process.html#data-quality-report"><i class="fa fa-check"></i><b>4.2</b> Data quality report</a><ul>
<li class="chapter" data-level="4.2.1" data-path="data-pre-process.html"><a href="data-pre-process.html#continuous-features"><i class="fa fa-check"></i><b>4.2.1</b> Continuous features</a></li>
</ul></li>
<li class="chapter" data-level="4.3" data-path="data-pre-process.html"><a href="data-pre-process.html#categorical-features-for-demographics-data"><i class="fa fa-check"></i><b>4.3</b> Categorical Features for demographics data</a><ul>
<li class="chapter" data-level="4.3.1" data-path="data-pre-process.html"><a href="data-pre-process.html#categorical-features-for-slepp-hygiene"><i class="fa fa-check"></i><b>4.3.1</b> Categorical features for Slepp hygiene</a></li>
</ul></li>
<li class="chapter" data-level="4.4" data-path="data-pre-process.html"><a href="data-pre-process.html#following-the-quality-plan-to-attend-issues"><i class="fa fa-check"></i><b>4.4</b> Following the quality plan to attend issues</a></li>
<li class="chapter" data-level="4.5" data-path="data-pre-process.html"><a href="data-pre-process.html#imputation-of-missing-values-in-sh-and-sq-features"><i class="fa fa-check"></i><b>4.5</b> Imputation of missing values in SH and SQ features</a></li>
<li class="chapter" data-level="4.6" data-path="data-pre-process.html"><a href="data-pre-process.html#final-results"><i class="fa fa-check"></i><b>4.6</b> Final results</a></li>
</ul></li>
<li class="chapter" data-level="5" data-path="feature-selection.html"><a href="feature-selection.html"><i class="fa fa-check"></i><b>5</b> <a href="feature-selection.html#feature-selection">Feature selection</a></a><ul>
<li class="chapter" data-level="5.1" data-path="feature-selection.html"><a href="feature-selection.html#feature-selection-models"><i class="fa fa-check"></i><b>5.1</b> <a href="#feature-selection-model">Feature selection models</a></a></li>
<li class="chapter" data-level="5.2" data-path="feature-selection.html"><a href="feature-selection.html#feature-selection-process"><i class="fa fa-check"></i><b>5.2</b> Feature selection process</a></li>
</ul></li>
<li class="chapter" data-level="6" data-path="evaluation-of-efficiency.html"><a href="evaluation-of-efficiency.html"><i class="fa fa-check"></i><b>6</b> <a href="#efficiency-evaluation">Evaluation of Efficiency</a></a><ul>
<li class="chapter" data-level="6.1" data-path="evaluation-of-efficiency.html"><a href="evaluation-of-efficiency.html#neural-networks-results"><i class="fa fa-check"></i><b>6.1</b> <a href="#NN-results">Neural Networks Results</a></a></li>
<li class="chapter" data-level="6.2" data-path="evaluation-of-efficiency.html"><a href="evaluation-of-efficiency.html#logistic-regression-results"><i class="fa fa-check"></i><b>6.2</b> <a href="#LR-results">Logistic Regression Results</a></a></li>
<li class="chapter" data-level="6.3" data-path="evaluation-of-efficiency.html"><a href="evaluation-of-efficiency.html#supprot-vector-machine-results"><i class="fa fa-check"></i><b>6.3</b> <a href="#SVM-results">Supprot Vector Machine Results</a></a></li>
<li class="chapter" data-level="6.4" data-path="evaluation-of-efficiency.html"><a href="evaluation-of-efficiency.html#comparing-the-results-of-the-three-algorithms-and-their-variants"><i class="fa fa-check"></i><b>6.4</b> Comparing the results of the three algorithms and their variants</a></li>
</ul></li>
<li class="chapter" data-level="7" data-path="applications.html"><a href="applications.html"><i class="fa fa-check"></i><b>7</b> Applications</a><ul>
<li class="chapter" data-level="7.1" data-path="applications.html"><a href="applications.html#example-one"><i class="fa fa-check"></i><b>7.1</b> Example one</a></li>
<li class="chapter" data-level="7.2" data-path="applications.html"><a href="applications.html#example-two"><i class="fa fa-check"></i><b>7.2</b> Example two</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="references.html"><a href="references.html"><i class="fa fa-check"></i>References</a></li>
<li class="chapter" data-level="8" data-path="final-words.html"><a href="final-words.html"><i class="fa fa-check"></i><b>8</b> Final Words</a></li>
<li class="divider"></li>
<li><a href="https://github.com/rstudio/bookdown" target="blank">Published with bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Sleep quality analysis</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="evaluation-of-efficiency" class="section level1">
<h1><span class="header-section-number">Chapter 6</span> <a href="#efficiency-evaluation">Evaluation of Efficiency</a></h1>
<p>Before testing the selected factors, models were trained using the 21 sleep hygiene factors to know the predictive efficiency that these models from various techniques of machine learning could achieve. The result was that both, the support vector machines (SVM) with linear kernel and logistic regression, were the two techniques with the best results. The SVM algorithm had an efficiency of 67% and the logistic regression reached an efficiency of 70%. With this background, the tests described below were made, taking into account only the four selected factors. If any of the techniques reaches an efficiency equal to or higher than the previous results, the selection of variables can be considered a successful process and these factors will be used for the prediction model of the study hereafter.</p>
<p>One of the steps in the development of the investigation project, includes the selection of a technique to train a predictive model on supervised automated learning. We did a review of the literature and we select three techniques under certain criterion based in the nature of the problem. The purpose is train the model with the available data and select the one given the best prediction. So, at the same time that the evaluation of efficience of the selected factors was performed, the selection of the technique that will be used for the final training was done. The three techniques that meet the inclusion criteria, were: artificial neural networks, vector supported machines And logistic regression with regularization. As in feature selection, a Shiny application was developed to process the data and compare the outcomes for these three algorithms, training a model with total of the records and only the four features selected in the feature selection process as was explained in Section <a href="feature-selection.html#feature-selection">5</a>.</p>
<p>The evaluation was performed by the cross validation technique using an iteration process of training, validation, analysis and refinement as the figure <a href="evaluation-of-efficiency.html#fig:cross-validation-process">6.1</a> shows. In this process a sixty percent of the data was used to train the model, when training conclude, the cross validation is performed through the prediction of the target variable in the cross validation set, containing a twenty percent of the main dataset. The analysis is done at that time and depending on the results, the parameters are adjusted to make a new iteration or reach the stop point. If the stop point was reached, the model is proved in the test set to obtain the final efficience of the model.</p>
<div class="figure" style="text-align: center"><span id="fig:cross-validation-process"></span>
<img src="images/cross-validation-process.png" alt="Cross Validation Process" width="80%" />
<p class="caption">
Figure 6.1: Cross Validation Process
</p>
</div>
<div id="neural-networks-results" class="section level2">
<h2><span class="header-section-number">6.1</span> <a href="#NN-results">Neural Networks Results</a></h2>
<p>Two neural networks were trained and validated by cross validation process, both estructures with a hidden layer. The first neural network had three neurons in the hidden layer and the second four neurons. The Fig. <a href="evaluation-of-efficiency.html#fig:nn-four-neurons">6.2</a> shows the structure of the neural network with four neurons in the input layer, one neuron for each factor selected in the feature selection process. The second layer is the hidden layer with four neurons and the last layer contains one neuron for the result (good sleep quality/bad sleep quality). Additionaly it is possible to observe the two activation neurons in the top of the figure.</p>
<div class="figure" style="text-align: center"><span id="fig:nn-four-neurons"></span>
<img src="images/nn-four-neurons.png" alt="Structure of neural network with four neurons in the hidden layer" width="80%" />
<p class="caption">
Figure 6.2: Structure of neural network with four neurons in the hidden layer
</p>
</div>
<p>The results for the two neural networks and the appropriate comparison between them, are in the Fig. <a href="evaluation-of-efficiency.html#fig:results-of-the-3-4-nn">6.3</a>. The network with better efficiency of two networks is the network with four neurons. The table describes that in the three sets, the behavior was superior in terms of efficiency, while the plot represents the error per each set with three and four neurons. CClearly, the lines decrease in favor of the training and validation with four neurons, where the error of the prediction is smaller.</p>
<div class="figure" style="text-align: center"><span id="fig:results-of-the-3-4-nn"></span>
<img src="images/results-of-the-3-4-nn.png" alt="Comparison of the results for the two trained neural networks" width="80%" />
<p class="caption">
Figure 6.3: Comparison of the results for the two trained neural networks
</p>
</div>
<p>The results of the neural network, satisfy the conditions sought, because although it is not greatly improved in efficiency when compared to what can be obtained by employing all the factors of sleep hygiene, we gain in the amount of factors that must be sensed to obtain input data. This fact has great relevance for the project because it greatly limits the design and infrastructure of the data acquisition module.</p>
</div>
<div id="logistic-regression-results" class="section level2">
<h2><span class="header-section-number">6.2</span> <a href="#LR-results">Logistic Regression Results</a></h2>
<p>We train the model through logistic regression (LR) with regularization parameter and polynomials of degree one, two and three, in order to look for the optimal point between over fit and bias. The regularization parameter based on the norm <span class="math inline">\(l_2\)</span> takes the form of the equation <a href="evaluation-of-efficiency.html#eq:regularization-parameter">(6.1)</a>, where <span class="math inline">\(\lambda\)</span> took values from 0.1 to 0.6 with intervals of 0.03 to choose the optimal value.</p>
<span class="math display" id="eq:regularization-parameter">\[\begin{equation}
  reg=\frac{\lambda}{2m}\sum_{j=2}^{n}\theta_j^2
  \tag{6.1}
\end{equation}\]</span>
<p>The stop condition for the adjustment of the parameters of the regression is of the order of one hundred thousandths, that is to say, while the previous and the current cost function did not have a difference of 0.00003 between both, the regression continued to iterate.</p>
<p>The results of LR’s are shown by the application in the format of the Fig. <a href="evaluation-of-efficiency.html#fig:lr-poly-1">6.4</a>. This figure shows the original results for the LR with the polynomial of degree one, we obtained five coeficients including the intercept coeficient, the right table have the data of prediction, <span class="math inline">\(70\%\)</span> of efficiency for the training set, <span class="math inline">\(76\%\)</span> for the cross validation set and <span class="math inline">\(69\%\)</span> in the test set. The plot in the top of figure, shows the behavior of the cost funtion through the iterations in the compute and refinement of the parameters.</p>
<div class="figure" style="text-align: center"><span id="fig:lr-poly-1"></span>
<img src="images/lr-poly-1.png" alt="Results of the LR and polynomial grade one" width="80%" />
<p class="caption">
Figure 6.4: Results of the LR and polynomial grade one
</p>
</div>
<p>For polynomials of degree two and three we have a similar figure, the difference is the number of coeficients that in the case of the polynomial of degree two are 16 and, in the polynomial of grade three are 35, including in both cases <em>dummy factors</em>. In the case of polynomial of degree two the cost function iterated 150 times and the predictions were <span class="math inline">\(72\%\)</span> of efficiency for the training set, <span class="math inline">\(78\%\)</span> for the cross validation set and <span class="math inline">\(69\%\)</span> for the test set. The LR with the polynomial of degree three, did 446 iterations, having a precision in the prediction of <span class="math inline">\(75\%\)</span> for the training set, <span class="math inline">\(70\%\)</span> for the cross validation set, falling to <span class="math inline">\(62\%\)</span> for the test set.</p>
<!-- table:tab: -->
<!-- |                      | degree 1 | degree 2 | degree 3 | -->
<!-- |----------------------|----------|----------|----------| -->
<!-- | training set         | 70 %     | 72 %     | 75 %     | -->
<!-- | cross validation set | 76 %     | 78 %     | 70 %     | -->
<!-- | test set             | 69 %     | 69 %     | 62 %     | -->

<p>Comparing the three results in the table <a href="#tab:results-of-efficiency-logistic-regression"><strong>??</strong></a>, we conclude that the polynomial of degree one is the best choice for this study, because, is the algorithm that consumes the lower resources of the processor and memory and have similar predictions than the other two models of degree two and three. Results, also are satisfactory if they are compared with the results using the 21 input data.</p>
</div>
<div id="supprot-vector-machine-results" class="section level2">
<h2><span class="header-section-number">6.3</span> <a href="#SVM-results">Supprot Vector Machine Results</a></h2>
<p>As in the previous algorithms, for support vector machines algorithm, a cross valitation test was performed. In this case, were used four kernels, two lineal kernels with polynomials of degree one and two, one radial kernel and one sigmoide kernel. The Fig. <a href="evaluation-of-efficiency.html#fig:SVM-sigmoide-2-flecha">6.5</a> shows the results as they are presnted in the Shinny application, we can see in the left panel, the plot showing diferents values of C and Gamma parameters and how is the behavior of the error depending of these two parameters. In the right side we observe that the best values for C is 0.04 and the best value for Gamma is 0.5 to reach the best prediction for this kernel, 76% of prediction in the test set.</p>
<div class="figure" style="text-align: center"><span id="fig:SVM-sigmoide-2-flecha"></span>
<img src="images/SVM-sigmoide-2-flecha.png" alt="Results of SVM with sigmoide kernel" width="80%" />
<p class="caption">
Figure 6.5: Results of SVM with sigmoide kernel
</p>
</div>
<p>The Table <a href="#tab:results-of-efficiency-svm"><strong>??</strong></a> show a comparative framework of results of the four kernels that were tested. We can observe that the sigmoid and radial are the best evaluated with a slight advantage of 3 percentage points of the sigmoid over the radial. The linear kernel is not a bad choice if one thinks in terms of simplicity to program it and the little memory and processor that consumes.</p>

<p>The Table <a href="#tab:results-of-efficiency-svm"><strong>??</strong></a>, also presents the best C and Gamma parameters that the cross validation process selected for these algorithm with different kernels, the parameter Gamma maintains its value in each one of the two kernels that is required (radial and sigmoide), 0.5 is the best value among the six values tested. On the other hand, the parameter C, shows that small values are more appropriate than big values. For C parameter, the best value is 0.40 for Radial kernel and 0.04 for sigmoide kernel. C was chosen in a range of 0.01 to 1000. It means that in both cases the algorithm selected a wide margin classifier.</p>
</div>
<div id="comparing-the-results-of-the-three-algorithms-and-their-variants" class="section level2">
<h2><span class="header-section-number">6.4</span> Comparing the results of the three algorithms and their variants</h2>
<p>The results of all algorithms and their variants are described in the Table <a href="#tab:results-of-all-algoritms"><strong>??</strong></a>. This table shows that all algorithms yielded similar results, the percentaje of pressicion in prediction of the categorical variable for the sleep quality is arround of 70%, which is also similar to the results using all factors involved in the hygiene of sleep taken in account in the SHI questionnaire.</p>

</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="feature-selection.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="applications.html" class="navigation navigation-next " aria-label="Next page""><i class="fa fa-angle-right"></i></a>

<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script>
require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"google": false,
"weibo": false,
"instapper": false,
"vk": false,
"all": ["facebook", "google", "twitter", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": "https://github.com/rstudio/bookdown-demo/edit/master/05-efficience-evaluation.Rmd",
"text": "Edit"
},
"download": ["bookdown-demo.pdf", "bookdown-demo.epub"],
"toc": {
"collapse": "subsection"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
    if (location.protocol !== "file:" && /^https?:/.test(script.src))
      script.src  = script.src.replace(/^https?:/, '');
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
